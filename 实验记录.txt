1. 炉号和膜厚设置值匹配对应好; model2的微调std index 和 std 修改值, 落盘并在运行modle1时自动读取 [done.!]



2. 增加一个, 我们算法model1,2 调优完成后, 所有数据lab ok 的数值?
[优先级较低], 因为我们模型优化推理得到的lab曲线,并不一定是真的镜片膜厚设置修改后会得到的曲线]





0726：
model2.py flag == 0, 单独处理每一个样本
1. 每个炉号的膜厚修改情况单独写入一个.txt, 所有的txt统一放文件夹下.



lab曲线好不好，非常依赖model2的flag=1的拟合好坏 


为什么,单独一条样本送进入 各个样本基本一样不受模型变化
但是集体样本送进去，样本件就会有差异？,难道还是scale的bug???,是的就是因为它！！！只有一个样本的时候，scale完x变全零....omg！！！
需要手动: x = (x-mean)/std


兜底方案: [效果很粗糙...]
model2也出现微调阶段训不动的情况 输入端的梯度都不变 
[感觉这个是很有必要的，毕竟不同的样本之间，需要区分的进行微调]
微调阶段的lr，可以尝试把代码写成超参搜索，达到一个模型自主选择的过程[这个是ok的~]
在model0726_2056.py中实现了~



思考为什么训不动? 
首先， 曲线变化了，证明data端一定是改变了的。 为什么训不动，可能是因为 81维度上，81个点的loss/grad 差异太大。应该根据std区分开? 
打印了下 每个epoch的梯度都不变的? 14维完全没变化

或者，还是因为model2的flag=1拟合的不好?????


分析:
14维的std, 非常非常微小的改变，会带来曲线很大的变化... mse也变化挺大的. 如: 0.82 -> 0.26 ... [这不就是model2.py flag == 1过拟合了...] 但, 也可能真的梯度不好传...



做一个14 std 到 10维曲线的映射?,看看改std对10维影响大不大???,[在loss里把剩余的71维weight置0就好~] [还是一样, std变化很微小很微小，但mse会有蛮大变化...]
梯度太大了???


猜想，model2的输入之间，太相似了, 数据标准话一下之后diff就更小了... 模型就很难学习好 x几乎一样，要去学出不同的y...[可视化一下所有的std x, flag=0阶段的...]
[猜想错误, X样本之间diff还挺大的...]

另外: 为什么一起放入微调, loss会出现一下下震荡 虽然是很数量级的 1e-5之类的... 可能浮点误差把....



1. 还是model2 flag=1没有拟合好...?????

比较粗糙的一个方案:
1. 保持现在的model2, flag=1用所有数据拟合, flag=0用大清洗内的数据微调. 虽然loss训不动, 即模型只在第一个epoch时候微调,
可将lr设置为搜索方式, [0.1, 0.5]范围, 得到最接近标准曲线的结果.


[-0.011027330404737648, -2.208806477669678, 6.622097480408985, -3.2976394279664483, 1.5343488411920534, 1.6141188966010322, 0.29986237455439585, -0.15545047819867958, -3.080210235829034, 6.733569497337689, -3.654895367395472, 2.0634
906119490273, 2.493694672091455, 0.33964004330412745] base
epoch 0, data: [9.627114343289009, 5.0495741234793945, 5.537281495528722, 12.744503803760189, 35.33844104788958, 35.66846629389466, 14.77861505547356, 9.347839212916213, 4.690999663843107, 5.5335705701323175, 12.458338763885454, 34.
77463461236881, 35.69159889415467, 14.836498464306066]
data value:,[-0.01102733 -2.2088065, 6.6220975,-3.2976394, 1.5343488, 1.6141189
,0.29986238 -0.15545048 -3.0802102, 6.7335696,-3.6548953, 2.0634906
,2.4936948, 0.33964005]

,std 1e-7级别的修改, loss那边的响应: 



尝试数据不做归一化处理?
flag=1 拟合出现"尖"频段突变, flag=0也基本不改变输入的原始std值

用了一条validation的数据做flag=0微调, 实验结果类似,应该也不是flag=1阶段过拟合的原因.[用了train中见过的数据做微调，所以flag=0训不动..]

另外发现的一个问题:
1. 微调阶段, y端使用标准曲线或本身样本的lab曲线, 模型输出的data调整结果都是一样的....[y端的变化很难体现到x端???]



0727下午 bug修复, 微调data阶段写错了... data端写死了.. 现在flag=0阶段是可训动的...




epochs - 1 保存std的修改值
epochs - 2 保存优化后的lab曲线
epoch_test = min_loss_index + 2



[0, 1, 2, 6, 8, 10, 12, 13]

['9.425756765370902', '6.181887926323517', '4.369867714469095', '12.928751934461658', '5.523693280069558', '12.94975895436975', '34.34616070029068', '14.772689997459405


[[ 25.3, 13.,,37.59 106.2, 96.2, 24.68,12.7, 36.67 103.9, 94.9 ]]
[[-2.92304886e+12 -4.72496495e-01,1.73475908e+13,3.69909836e-01
, 6.21964638e+00,0.00000000e+00 -1.54735694e-01,5.86962124e-01
, 4.10325508e-01,7.03396126e+00]]



, [ 25.35,12.96,37.17 106.4, 93.4, 24.68,12.62,36.67 103.6, 92.4 ] ==

[-0.41539023 -1.04446594,0.58696212,0.49145164 -1.19785782,0.
 -1.04446594,0.58696212,0.18562344 -0.31972551] ==



 不应该用一个周期内的thickness mean 和 std 而是用所有样本的 [在model2.py中就记录下来...,不然std值太小了...],[done.]






利群样本拉出来试试，看调整效果,[ok的~]
线上通路是否可调.. 代码足够自动化。


算法运行步骤: 
1. 全量数据, model2.py flag=1, 拟合sensor std值到lab曲线的模型 
2. data_clean_cycle.py 生成一个大清洗周期内的所有炉号.
3. model2.py flag=0
, model2.py flag=2, lab曲线调优
4. thickness10_modified.py flag=1,std修改值统计

5. 使用一个大清洗周期内的所有数据去, data_clean_cycle_model1.py flag = 1 拟合膜厚到lab值关系
data_clean_cycle_model1.py flag = 0
data_clean_cycle_model1.py flag = 2
thickness10_modified.py flag=2




# 0729 
【模型最后需要优化的项: model2 flag=1的拟合, 需要更准确, loss降低要0.5以内最佳!!!】


部署流程走一下：
to do list:
1. 继续优化model1的拟合, [ok, lr=0.001就差不多..~]
2. 1月的 '33321012501' 测试算法
3. 把所有清洗周期分出来, 然后各个model1 flag==1的mlp.pth落盘
细节: 
model1的flag=1使用全部的大清洗周期内的数据拟合, 但拟合的std index是单个样本的std index..
所以需要代码过一遍整个清洗周期内的数据, 然后汇总需要拟合的indexs,
再根据这些index, 用所有的周期数据拟合model1, 落盘.pth [lr:0.001就差不多可以]
[注意,这一步拟合model1,部分数值没拟合上也不用太担心, 本来index就是所有样本的一个set集合~ ]
新来一个样本, 在所有model1.pth中找最接近的那个.pth, 然后继续modle1的 flag=0,2调优~



1. 蔡司膜厚推优项目算法打通，在完善线上部署代码，本周五下午给到客户反馈，开始推进线上测试验证
2. 首次接触安世半导体投标项(工业调度生产问题)，正在理解数据和问题背景。

1. 跟踪蔡司反馈, 继续算法部署，配合软件开发等工作...
2. 安世半导体投标项继续理解+初步处理数据。

蔡司项目confluence文档: http://192.168.5.103:8090/pages/viewpage.action?pageId=22675710




数据需求: 
1. 本产品数据持续供给. (刚会议澄清的,model1分周期拆分建模, 所以需要比较多的数据支持新样本选择最接近的机器状态)
2. 等待差异数据(膜厚到曲线, 曲线到膜厚.) 我们这边会使用model1,2结合验证.
线上验证: 
1. 等待产线online验证.. 





0731 / 0801 to do list:
1. deta 方案可以尝试
2. 根据loss 降序排序, 洗出若干不同的model1.pth(而不是清洗周期..) 
3. 安世..


# 0731 关于验证模型效果和正背面修改推荐方向一致性的问题
遗留问题:
1. 0731李工补充:
如果没有正被差，说明两个面的颜色是一样的，那么他们的调节方向也应该一样，当然也有可能有不同的解，不过我担心这个会引入正背差
【正背面的调节方向是否一致是个问题. 会生产出两面, 说明正面的单面曲线是ok的, 但正背面设置值不同, 多少都是会产生正背面色差吧? 会单独测一下背面的曲线orlab
值吗? 技术上是可操作的吗? 】
李工解答:
由于镜片是有弧度的，所以正背面膜厚设置肯定不一样才可能得到同样的膜色。大体上背面会比正面多1-2%左右吧

结论: 
好的了解了。那比较直观的理解来说，还是尽量希望正背面膜厚调节方向是一致对的。因为目前给到的都是测量过的无正背色差数据。 


0731实验记录: 
1. 理论上, 蔡司给的3条测试数据, 属于同一个清洗周期比较正常[这个倒是都是, 都最接近model1中的index=6, 是个好消息..]
2. 找到最接近的model1状态后,要去finetune下model1, 不然效果很差...
3. 那就把3条都加进去finetune呗.,加了,还是有点偏差....



# 分步走吧..
1. 直接用三条数据的真实std值,输入model2, 看看lab情况是否和真实lab一致,检验model2的正确性.,model2就有点不准...
[还没办法finetune, 他们真实lab曲线没给到...]
[猜想: model2也和清洗周期有关系, 将validation和train根据周期划分, 0~3validation, 4~16train.]
会有个问题, model2的数据量就会小一些些(少了10条而已, 有578条), 因为第三批数据中的一些炉号和周期对不上,周期性未知..

2. model1的不准倒是可以通过loss直接体现出来, 并且finetune后loss会小挺多的..

0802:
需要把model2也按照周期拆分开...
mm_Model2_data_cycle.py
1.所有的数据先train有个base总model2.pth出来, 然后各个子周期的数据去做fine_tune,保存为新的16个model2_{}.pth
为什么这么干呢? 不做finetune直接训每个cycle数据的话, 数据量太少了,每个cycle模型的拟合效果不会太好.. 



test： 33321020305,cycle 0





0802：
model1很依赖测试数据的fine-tune. [即选中了最贴近的model1_{}.pth, 然后还是要拿测试数据去fine-tune下这个子模型, loss下降会很明显.
loss 十几甚至几十, 可以降到1一下]
[猜想: 可能因为, 本身model1的各个子模型,见的数据都比较少,fine-tune会是个很必要的过程..]


[model1没必要做all data base model训练再单独每一个data cycle finetune...]???? 存疑, 晚上试试看, 效果会不会更好.



过来的一条测试数据, model1要fine-tune, model2不要.




# 0803 
根据lab曲线去逼近: 
24.11 5 12.42 36.85 102.73 93.9325 25.07 5 13.20 37.19 104.42 94.26 25



根据R3去逼近:
正面: 24.08 5 12.57 36.86 104.00 93.48 25 
背面: 25.06 5 13.15 37.21 104.60 94.08 25

24.46   5   11.7    36.34   102.2   93.6    25      24.95   5   12.4    37.07   107.65  97.1    25
24.46   5   11.7    36.34   101.5   93.95   25      24.9    4.99    12.38   36.99   105.8   95.8    25



1. 数据需求:
扩充加鲁棒 model1 model2


2.寻找model1的loss最小, 然后就找到了part_data_cycle{}.txt 
part_data_cycle{}.txt + 本条测试样本, 然后去拟合本样本显著改变的几个std值.
再计算膜厚修改值..




# 0803 结论:
1. 正向验证, model12均需要用测试数据fine-tune最佳model12
2. 反向验证, model12均不需要用测试数据fine-tune最佳model12

# 0803晚上  to do list. 
3. deta 方案可以尝试
2. 根据loss 降序排序, 洗出若干不同的model1.pth(而不是清洗周期..) 



